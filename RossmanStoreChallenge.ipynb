{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RossmanStoreChallenge.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/herwinvw/rossman_store_sales_challenge/blob/master/RossmanStoreChallenge.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "avx1EQDuHJhZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Kaggle Rossmann Store Sales challenge\n",
        "\n",
        "Trying out the entitie-embedding from https://github.com/entron/entity-embedding-rossmann.\n"
      ]
    },
    {
      "metadata": {
        "id": "df-OHpqYG67H",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Select the 5 .csv from the Rossman Store Sales Challenge (https://www.kaggle.com/c/rossmann-store-sales) for upload."
      ]
    },
    {
      "metadata": {
        "id": "lJ-iPBmoGT49",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": "OK"
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "outputId": "5cd183bf-a146-4c41-f35a-146961156840"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-be2e3462-1a4b-4679-8197-dba8a01c7dcb\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-be2e3462-1a4b-4679-8197-dba8a01c7dcb\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving sample_submission.csv to sample_submission (1).csv\n",
            "Saving store.csv to store (1).csv\n",
            "Saving store_states.csv to store_states (1).csv\n",
            "Saving test.csv to test (1).csv\n",
            "Saving train.csv to train (1).csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-qj7022cLijK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "uploaded"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eB2gErYOIEMq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Extract .csv files"
      ]
    },
    {
      "metadata": {
        "id": "bQixNrJmIKgv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import csv\n",
        "import io"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RWIAIVVqI4QS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def csv2dicts(csvfile):\n",
        "    data = []\n",
        "    keys = []\n",
        "    for row_index, row in enumerate(csvfile):\n",
        "        if row_index == 0:\n",
        "            keys = row\n",
        "            print(row)\n",
        "            continue\n",
        "        if row_index % 10000 == 0:\n",
        "            print(row_index)\n",
        "        data.append({key: value for key, value in zip(keys, row)})\n",
        "    return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zeUxNzmyI-eh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def set_nan_as_string(data, replace_str='0'):\n",
        "    for i, x in enumerate(data):\n",
        "        for key, value in x.items():\n",
        "            if value == '':\n",
        "                x[key] = replace_str\n",
        "        data[i] = x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HvD6ZhkyJBZj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_data = \"train.csv\"\n",
        "store_data = \"store.csv\"\n",
        "store_states = 'store_states.csv'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1uxRYBdtJDox",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1929
        },
        "outputId": "b1411c9c-611b-4daf-8285-6b9b3f74a8f8"
      },
      "cell_type": "code",
      "source": [
        "with io.StringIO(uploaded['train.csv'].decode('utf-8')) as csvfile:\n",
        "    data = csv.reader(csvfile, delimiter=',')\n",
        "    with open('train_data.pickle', 'wb') as f:\n",
        "        data = csv2dicts(data)\n",
        "        data = data[::-1]\n",
        "        pickle.dump(data, f, -1)\n",
        "        print(data[:3])"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Store', 'DayOfWeek', 'Date', 'Sales', 'Customers', 'Open', 'Promo', 'StateHoliday', 'SchoolHoliday']\n",
            "10000\n",
            "20000\n",
            "30000\n",
            "40000\n",
            "50000\n",
            "60000\n",
            "70000\n",
            "80000\n",
            "90000\n",
            "100000\n",
            "110000\n",
            "120000\n",
            "130000\n",
            "140000\n",
            "150000\n",
            "160000\n",
            "170000\n",
            "180000\n",
            "190000\n",
            "200000\n",
            "210000\n",
            "220000\n",
            "230000\n",
            "240000\n",
            "250000\n",
            "260000\n",
            "270000\n",
            "280000\n",
            "290000\n",
            "300000\n",
            "310000\n",
            "320000\n",
            "330000\n",
            "340000\n",
            "350000\n",
            "360000\n",
            "370000\n",
            "380000\n",
            "390000\n",
            "400000\n",
            "410000\n",
            "420000\n",
            "430000\n",
            "440000\n",
            "450000\n",
            "460000\n",
            "470000\n",
            "480000\n",
            "490000\n",
            "500000\n",
            "510000\n",
            "520000\n",
            "530000\n",
            "540000\n",
            "550000\n",
            "560000\n",
            "570000\n",
            "580000\n",
            "590000\n",
            "600000\n",
            "610000\n",
            "620000\n",
            "630000\n",
            "640000\n",
            "650000\n",
            "660000\n",
            "670000\n",
            "680000\n",
            "690000\n",
            "700000\n",
            "710000\n",
            "720000\n",
            "730000\n",
            "740000\n",
            "750000\n",
            "760000\n",
            "770000\n",
            "780000\n",
            "790000\n",
            "800000\n",
            "810000\n",
            "820000\n",
            "830000\n",
            "840000\n",
            "850000\n",
            "860000\n",
            "870000\n",
            "880000\n",
            "890000\n",
            "900000\n",
            "910000\n",
            "920000\n",
            "930000\n",
            "940000\n",
            "950000\n",
            "960000\n",
            "970000\n",
            "980000\n",
            "990000\n",
            "1000000\n",
            "1010000\n",
            "[{'Store': '1115', 'DayOfWeek': '2', 'Date': '2013-01-01', 'Sales': '0', 'Customers': '0', 'Open': '0', 'Promo': '0', 'StateHoliday': 'a', 'SchoolHoliday': '1'}, {'Store': '1114', 'DayOfWeek': '2', 'Date': '2013-01-01', 'Sales': '0', 'Customers': '0', 'Open': '0', 'Promo': '0', 'StateHoliday': 'a', 'SchoolHoliday': '1'}, {'Store': '1113', 'DayOfWeek': '2', 'Date': '2013-01-01', 'Sales': '0', 'Customers': '0', 'Open': '0', 'Promo': '0', 'StateHoliday': 'a', 'SchoolHoliday': '1'}]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OpW5OuNvKd3v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "outputId": "cd35a23d-e638-43f2-9e2d-176605b72c16"
      },
      "cell_type": "code",
      "source": [
        "with open(store_data) as csvfile, open(store_states) as csvfile2:\n",
        "    data = csv.reader(csvfile, delimiter=',')\n",
        "    state_data = csv.reader(csvfile2, delimiter=',')\n",
        "    with open('store_data.pickle', 'wb') as f:\n",
        "        data = csv2dicts(data)\n",
        "        state_data = csv2dicts(state_data)\n",
        "        set_nan_as_string(data)\n",
        "        for index, val in enumerate(data):\n",
        "            state = state_data[index]\n",
        "            val['State'] = state['State']\n",
        "            data[index] = val\n",
        "        pickle.dump(data, f, -1)\n",
        "        print(data[:2])"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Store', 'StoreType', 'Assortment', 'CompetitionDistance', 'CompetitionOpenSinceMonth', 'CompetitionOpenSinceYear', 'Promo2', 'Promo2SinceWeek', 'Promo2SinceYear', 'PromoInterval']\n",
            "['Store', 'State']\n",
            "[{'Store': '1', 'StoreType': 'c', 'Assortment': 'a', 'CompetitionDistance': '1270', 'CompetitionOpenSinceMonth': '9', 'CompetitionOpenSinceYear': '2008', 'Promo2': '0', 'Promo2SinceWeek': '0', 'Promo2SinceYear': '0', 'PromoInterval': '0', 'State': 'HE'}, {'Store': '2', 'StoreType': 'a', 'Assortment': 'a', 'CompetitionDistance': '570', 'CompetitionOpenSinceMonth': '11', 'CompetitionOpenSinceYear': '2007', 'Promo2': '1', 'Promo2SinceWeek': '13', 'Promo2SinceYear': '2010', 'PromoInterval': 'Jan,Apr,Jul,Oct', 'State': 'TH'}]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vHuWxM11VBLX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Prepare features"
      ]
    },
    {
      "metadata": {
        "id": "PuiQERvvVDxe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "from datetime import datetime\n",
        "from sklearn import preprocessing\n",
        "import numpy as np\n",
        "import random\n",
        "random.seed(42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "W8VdrhKeVGnZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with open('train_data.pickle', 'rb') as f:\n",
        "    train_data = pickle.load(f)\n",
        "    num_records = len(train_data)\n",
        "with open('store_data.pickle', 'rb') as f:\n",
        "    store_data = pickle.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jNgaLvIQVJtB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def feature_list(record):\n",
        "    dt = datetime.strptime(record['Date'], '%Y-%m-%d')\n",
        "    store_index = int(record['Store'])\n",
        "    year = dt.year\n",
        "    month = dt.month\n",
        "    day = dt.day\n",
        "    day_of_week = int(record['DayOfWeek'])\n",
        "    try:\n",
        "        store_open = int(record['Open'])\n",
        "    except:\n",
        "        store_open = 1\n",
        "\n",
        "    promo = int(record['Promo'])\n",
        "\n",
        "    return [store_open,\n",
        "            store_index,\n",
        "            day_of_week,\n",
        "            promo,\n",
        "            year,\n",
        "            month,\n",
        "            day,\n",
        "            store_data[store_index - 1]['State']\n",
        "            ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "J3pOG5O9VMTU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_data_X = []\n",
        "train_data_y = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9NZg3xLHVNrg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for record in train_data:\n",
        "    if record['Sales'] != '0' and record['Open'] != '':\n",
        "        fl = feature_list(record)\n",
        "        train_data_X.append(fl)\n",
        "        train_data_y.append(int(record['Sales']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "airVru3nVQiN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "2f0fb0b9-e073-4f4c-8ac4-303c9f5d07d0"
      },
      "cell_type": "code",
      "source": [
        "print(\"Number of train datapoints: \", len(train_data_y))\n",
        "print(min(train_data_y), max(train_data_y))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of train datapoints:  844338\n",
            "46 41551\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OKfGgcNPVSwI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "full_X = train_data_X\n",
        "full_X = np.array(full_X)\n",
        "train_data_X = np.array(train_data_X)\n",
        "les = []\n",
        "for i in range(train_data_X.shape[1]):\n",
        "    le = preprocessing.LabelEncoder()\n",
        "    le.fit(full_X[:, i])\n",
        "    les.append(le)\n",
        "    train_data_X[:, i] = le.transform(train_data_X[:, i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RLu264yKVXNw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with open('les.pickle', 'wb') as f:\n",
        "    pickle.dump(les, f, -1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dWBPGN49bHTS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_data_X = train_data_X.astype(int)\n",
        "train_data_y = np.array(train_data_y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "di3XY8j0aBt4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e4b8006b-3d41-46f1-8e1a-dffdd9820221"
      },
      "cell_type": "code",
      "source": [
        "with open('feature_train_data.pickle', 'wb') as f:\n",
        "    pickle.dump((train_data_X, train_data_y), f, -1)\n",
        "    print(train_data_X[0], train_data_y[0])"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[  0 109   1   0   0   0   0   7] 5961\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "IM5gfN2Qbyka",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Model definition"
      ]
    },
    {
      "metadata": {
        "id": "VV_Qq8xVb5Vh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "13435db3-9f13-453f-c1c9-d8d5b11dad76"
      },
      "cell_type": "code",
      "source": [
        "import numpy\n",
        "numpy.random.seed(123)\n",
        "from sklearn import linear_model\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import xgboost as xgb\n",
        "from sklearn import neighbors\n",
        "from sklearn.preprocessing import Normalizer\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.models import Model as KerasModel\n",
        "from keras.layers import Input, Dense, Activation, Reshape\n",
        "from keras.layers import Concatenate\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.callbacks import ModelCheckpoint"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "yF7t7LSqcd7h",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def split_features(X):\n",
        "    X_list = []\n",
        "\n",
        "    store_index = X[..., [1]]\n",
        "    X_list.append(store_index)\n",
        "\n",
        "    day_of_week = X[..., [2]]\n",
        "    X_list.append(day_of_week)\n",
        "\n",
        "    promo = X[..., [3]]\n",
        "    X_list.append(promo)\n",
        "\n",
        "    year = X[..., [4]]\n",
        "    X_list.append(year)\n",
        "\n",
        "    month = X[..., [5]]\n",
        "    X_list.append(month)\n",
        "\n",
        "    day = X[..., [6]]\n",
        "    X_list.append(day)\n",
        "\n",
        "    State = X[..., [7]]\n",
        "    X_list.append(State)\n",
        "\n",
        "    return X_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_C78TZlucK5C",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Model(object):\n",
        "\n",
        "    def evaluate(self, X_val, y_val):\n",
        "        assert(min(y_val) > 0)\n",
        "        guessed_sales = self.guess(X_val)\n",
        "        relative_err = numpy.absolute((y_val - guessed_sales) / y_val)\n",
        "        result = numpy.sum(relative_err) / len(y_val)\n",
        "        return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PpLTPiKOb8EL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class NN_with_EntityEmbedding(Model):\n",
        "\n",
        "    def __init__(self, X_train, y_train, X_val, y_val):\n",
        "        super().__init__()\n",
        "        self.epochs = 10\n",
        "        self.checkpointer = ModelCheckpoint(filepath=\"best_model_weights.hdf5\", verbose=1, save_best_only=True)\n",
        "        self.max_log_y = max(numpy.max(numpy.log(y_train)), numpy.max(numpy.log(y_val)))\n",
        "        self.__build_keras_model()\n",
        "        self.fit(X_train, y_train, X_val, y_val)\n",
        "\n",
        "    def preprocessing(self, X):\n",
        "        X_list = split_features(X)\n",
        "        return X_list\n",
        "\n",
        "    def __build_keras_model(self):\n",
        "        input_store = Input(shape=(1,))\n",
        "        output_store = Embedding(1115, 10, name='store_embedding')(input_store)\n",
        "        output_store = Reshape(target_shape=(10,))(output_store)\n",
        "\n",
        "        input_dow = Input(shape=(1,))\n",
        "        output_dow = Embedding(7, 6, name='dow_embedding')(input_dow)\n",
        "        output_dow = Reshape(target_shape=(6,))(output_dow)\n",
        "\n",
        "        input_promo = Input(shape=(1,))\n",
        "        output_promo = Dense(1)(input_promo)\n",
        "\n",
        "        input_year = Input(shape=(1,))\n",
        "        output_year = Embedding(3, 2, name='year_embedding')(input_year)\n",
        "        output_year = Reshape(target_shape=(2,))(output_year)\n",
        "\n",
        "        input_month = Input(shape=(1,))\n",
        "        output_month = Embedding(12, 6, name='month_embedding')(input_month)\n",
        "        output_month = Reshape(target_shape=(6,))(output_month)\n",
        "\n",
        "        input_day = Input(shape=(1,))\n",
        "        output_day = Embedding(31, 10, name='day_embedding')(input_day)\n",
        "        output_day = Reshape(target_shape=(10,))(output_day)\n",
        "\n",
        "        input_germanstate = Input(shape=(1,))\n",
        "        output_germanstate = Embedding(12, 6, name='state_embedding')(input_germanstate)\n",
        "        output_germanstate = Reshape(target_shape=(6,))(output_germanstate)\n",
        "\n",
        "        input_model = [input_store, input_dow, input_promo,\n",
        "                       input_year, input_month, input_day, input_germanstate]\n",
        "\n",
        "        output_embeddings = [output_store, output_dow, output_promo,\n",
        "                             output_year, output_month, output_day, output_germanstate]\n",
        "\n",
        "        output_model = Concatenate()(output_embeddings)\n",
        "        output_model = Dense(1000, kernel_initializer=\"uniform\")(output_model)\n",
        "        output_model = Activation('relu')(output_model)\n",
        "        output_model = Dense(500, kernel_initializer=\"uniform\")(output_model)\n",
        "        output_model = Activation('relu')(output_model)\n",
        "        output_model = Dense(1)(output_model)\n",
        "        output_model = Activation('sigmoid')(output_model)\n",
        "\n",
        "        self.model = KerasModel(inputs=input_model, outputs=output_model)\n",
        "\n",
        "        self.model.compile(loss='mean_absolute_error', optimizer='adam')\n",
        "\n",
        "    def _val_for_fit(self, val):\n",
        "        val = numpy.log(val) / self.max_log_y\n",
        "        return val\n",
        "\n",
        "    def _val_for_pred(self, val):\n",
        "        return numpy.exp(val * self.max_log_y)\n",
        "\n",
        "    def fit(self, X_train, y_train, X_val, y_val):\n",
        "        self.model.fit(self.preprocessing(X_train), self._val_for_fit(y_train),\n",
        "                       validation_data=(self.preprocessing(X_val), self._val_for_fit(y_val)),\n",
        "                       epochs=self.epochs, batch_size=128,\n",
        "                       # callbacks=[self.checkpointer],\n",
        "                       )\n",
        "        # self.model.load_weights('best_model_weights.hdf5')\n",
        "        print(\"Result on validation data: \", self.evaluate(X_val, y_val))\n",
        "\n",
        "    def guess(self, features):\n",
        "        features = self.preprocessing(features)\n",
        "        result = self.model.predict(features).flatten()\n",
        "        return self._val_for_pred(result)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mjpW5Gy8ahl6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Train"
      ]
    },
    {
      "metadata": {
        "id": "fS2uVZz6aizm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import numpy\n",
        "numpy.random.seed(123)\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import sys\n",
        "sys.setrecursionlimit(10000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BduL943casjG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_ratio = 0.9\n",
        "shuffle_data = False\n",
        "one_hot_as_input = False\n",
        "embeddings_as_input = False\n",
        "save_embeddings = True\n",
        "saved_embeddings_fname = \"embeddings.pickle\"  # set save_embeddings to True to create this file"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Pa7Z4x_razfJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "f = open('feature_train_data.pickle', 'rb')\n",
        "(X, y) = pickle.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CUKcqJeCa01D",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "num_records = len(X)\n",
        "train_size = int(train_ratio * num_records)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qaPF4dALbQOZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if shuffle_data:\n",
        "    print(\"Using shuffled data\")\n",
        "    sh = numpy.arange(X.shape[0])\n",
        "    numpy.random.shuffle(sh)\n",
        "    X = X[sh]\n",
        "    y = y[sh]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HDQ3BujVbViX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train = X[:train_size]\n",
        "X_val = X[train_size:]\n",
        "y_train = y[:train_size]\n",
        "y_val = y[train_size:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "d7Z53NJ9cRcS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Fitting NN with EntityEmbedding"
      ]
    },
    {
      "metadata": {
        "id": "zIeYT4RAcVLH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "e0c10eaf-4aad-4a11-8c7f-db2597ab14b7"
      },
      "cell_type": "code",
      "source": [
        "model_nn_with_entity_embedding = NN_with_EntityEmbedding(X_train, y_train, X_val, y_val)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 759904 samples, validate on 84434 samples\n",
            "Epoch 1/10\n",
            "192384/759904 [======>.......................] - ETA: 1:23 - loss: 0.0144"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8zRbErBscam7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}